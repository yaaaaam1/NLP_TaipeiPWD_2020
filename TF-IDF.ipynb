{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.dia import dia_matrix\n",
    "from scipy.sparse import vstack \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://clay-atlas.com/blog/2019/09/24/python-chinese-tutorial-ckiptagger/\n",
    "# from ckiptagger import WS, POS, NER\n",
    "\n",
    "# ws = WS(\"./data\")\n",
    "# pos = POS(\"./data\")\n",
    "# ner = NER(\"./data\")\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    rule = re.compile(r'[^a-zA-Z0-9\\u4e00-\\u9fa5]')\n",
    "    text = rule.sub(' ',str(text))\n",
    "    return text\n",
    "# https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/356827/\n",
    "\n",
    "# Define a function for cutting words \n",
    "def chinese_word_seg(text):\n",
    "    return \" \".join(jieba.cut(text,HMM = True)) # using HMM method\n",
    "\n",
    "def Preprocess(text):\n",
    "    text = chinese_word_seg(remove_punctuation(text))\n",
    "    text = ' '.join(text.split())\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"200801至202008缺失類型.xlsx\", sheets = \"法規\")\n",
    "\n",
    "def df_Preprocessing(df):\n",
    "    # rename columns\n",
    "    df.columns = [col.split(\"\\n\",1)[1] for col in df.columns]\n",
    "    # select None-NA data\n",
    "    df = df[(df.CE_Item2.isnull()==False) & (df.Ex_Tittle.isnull() == False)]\n",
    "    # drop useless columns\n",
    "    df.drop(columns = ['CE_CI_Block','CE_Item3','CE_Item4','CE_Item5'],inplace = True)\n",
    "    df = df[df.Ex_Tittle.isin(['政府採購法','政府採購法施行細則','採購評選委員會審議規則','採購評選委員會組織準則'])]\n",
    "#     df[\"tokenize\"] = df.CE_Comment.apply(Preprocess)\n",
    "    df['CE_Item2'] = df['CE_Item2'].apply(lambda string: str(string).partition(' ')[0])\n",
    "#     df['recommend']= df.apply(lambda x: '%s_%s' % (x['Ex_Tittle'],x['CE_Item2']),axis = 1)\n",
    "    return df\n",
    "\n",
    "df = df_Preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'本次契約變更案部分內容係增列 水保監造服務費  惟本採購案原屬細部設計顧問服務 如當初評選項目僅針對廠商提供之 細部設計顧問 DDC  標的為主 契約變更將 監造服務 納入 是否符合政府採購法第22條第1項第4款 原有採購 之規定 請檢討澄釋  政府採購法第22條第1項第4款 '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.CE_Comment.apply(remove_punctuation).iloc[60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVecotizer (Text Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(strip_accents = None)\n",
    "tf = tf_vectorizer.fit_transform(df['tokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(tf_vectorizer.get_feature_names())\n",
    "weight = tf.toarray().sum(axis = 0)\n",
    "wordfq = pd.DataFrame({'word':words,'freq':weight})\n",
    "wordfq.sort_values(by = 'freq',inplace = True, ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf\n",
    "https://stackabuse.com/text-classification-with-python-and-scikit-learn/ <br>\n",
    "https://stackoverflow.com/questions/44461931/adding-a-new-document-to-the-term-document-matrix-for-similarity-calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "tfidf_matrix = tf.fit_transform(df['tokenize'])\n",
    "cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "vocab = tf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtext = \"一直新增唷\"\n",
    "def addtext(text, vocab = vocab, tfidf_matrix = tfidf_matrix):\n",
    "    tf = TfidfVectorizer(vocabulary = vocab)\n",
    "    new_tf = tf.fit_transform([Preprocess(text)]) \n",
    "    # print(p_new.shape)\n",
    "    new_tfidf_matrix = vstack([tfidf_matrix,new_tf])\n",
    "    cossim = cosine_similarity(new_tfidf_matrix, new_tfidf_matrix)\n",
    "    newvocab = tf.vocabulary_\n",
    "    return newvocab, new_tfidf_matrix, cossim \n",
    "\n",
    "vocab, tfidf_matrix, cos_sim = addtext(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "1. 先新增至tfidf找相近text \n",
    "2. 對應至df的law\n",
    "3. 經專業人員判斷後再填寫正確法律回dataframe <br>\n",
    "https://stackoverflow.com/questions/8897593/how-to-compute-the-similarity-between-two-text-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform back to dataframe - law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(df.index)\n",
    "\n",
    "def recommendations(entered, cosine_sim = cos_sim):\n",
    "    recommended_law = []\n",
    "    index = indices[indices == entered].index[0]\n",
    "    similarity_scores = pd.Series(cosine_sim[index].sort_values(ascending = False))\n",
    "    top_10_law = list(similarity_scores.iloc[1:11].index)\n",
    "    for i in top_10_law:\n",
    "        recommended_law.append(list(df.index)[i])\n",
    "    return recommended_law\n",
    "# https://www.geeksforgeeks.org/movie-recommender-based-on-plot-summary-using-tf-idf-vectorization-and-cosine-similarity/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
